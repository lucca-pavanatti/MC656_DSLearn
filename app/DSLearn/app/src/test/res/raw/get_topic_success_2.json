{
  "content": [
    {
      "name": "Dynamic Programming",
      "contentMarkdown": "# Programação Dinâmica contentMarkdown"
    },
    {
      "name": "Two Pointers",
      "contentMarkdown": "# Dois Ponteiros\n\nA técnica dos **Dois Ponteiros** é uma abordagem eficiente para resolver problemas que envolvem arrays ou listas, onde dois índices percorrem a estrutura simultaneamente para buscar, comparar ou rearranjar elementos. Seu principal objetivo é reduzir a complexidade temporal evitando o uso de loops aninhados.\n\n## Como Funciona\n\nA técnica dos dois ponteiros utiliza duas variáveis indicadoras que percorrem o array ou lista em direções específicas. Geralmente, esses ponteiros se movem a partir de extremos opostos ou de posições iniciais diferentes, dependendo do problema. Conforme avançam, eles processam ou comparam elementos para atingir uma condição desejada.\n\nEssa técnica é especialmente útil para problemas que envolvem o processamento de sequências ordenadas ou que necessitam verificar pares de elementos, removendo duplicatas, rearranjando ou somando valores que satisfaçam algum critério.\n\nUma analogia simples é pensar em dois corredores em uma pista que começam em pontos diferentes e avançam até se encontrarem ou completarem a corrida, colaborando para cumprir uma tarefa conjunta.\n\n### Etapas Chave da Técnica dos Dois Ponteiros\n\n- Inicialização dos dois ponteiros em posições relevantes (ex: início e fim da lista).\n- Movimentação controlada dos ponteiros conforme regras do problema (incrementar, decrementar ou avançar conforme condição).\n- Avaliação dos elementos em cada posição para tomada de decisão.\n- Possível modificação da estrutura de dados ou acumulação do resultado.\n\n## Exemplo Visual\n\n![Exemplo visual para Two Pointers](https://i.postimg.cc/rsf000zn/two-pointers.png)\n\n## Operações Comuns\n\n- Encontrar pares em um array que somam um valor alvo.\n- Remover elementos duplicados ou indesejados em listas ordenadas.\n- Verificar se uma string ou array possui propriedades específicas (ex: palíndromo).\n- Mover elementos para uma posição específica (ex: zeros para o fim da lista).\n- Merge de arrays ordenados.\n\n\n## Implementação (Python)\n\n```python\n# Exemplo: encontrar se existe um par em um array ordenado que soma um valor alvo\n\ndef existe_par_com_soma(arr, alvo):\n    esquerda, direita = 0, len(arr) - 1\n    while esquerda < direita:\n        soma = arr[esquerda] + arr[direita]\n        if soma == alvo:\n            return True  # Par encontrado\n        elif soma < alvo:\n            esquerda += 1  # Mover ponteiro esquerdo para frente\n        else:\n            direita -= 1  # Mover ponteiro direito para trás\n    return False  # Nenhum par encontrado\n\n# Testando a função\nprint(existe_par_com_soma([1, 2, 4, 4, 7, 11], 8))  # Saída: True\n```\n\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n- Reduz complexidade de algoritmos que seriam quadráticos para linear.\n- Fácil implementação para problemas com dados ordenados.\n- Pode ser adaptado para diversos tipos de problemas envolvendo arrays e strings.\n\n**Desvantagens:**\n\n- Funciona melhor com dados ordenados ou que permitam movimentação lógica dos ponteiros.\n- Nem sempre aplicável para problemas que não possuem estrutura linear ou condições claras para movimentação dos ponteiros.\n\n\n## Uso e Aplicações\n\n- Verificação de pares com soma específica.\n- Ordenação e merge de arrays.\n- Remoção de duplicatas em listas ordenadas.\n- Validação de palíndromos em strings.\n- Manipulação de estruturas lineares para atender restrições específicas.\n\n\n## Complexidade\n\n- Tempo: O(n), já que cada ponteiro percorre o array no máximo uma vez.\n- Espaço: O(1), pois utiliza apenas variáveis auxiliares para os ponteiros e não aloca estruturas adicionais significativas.\n\n"
    },
    {
      "name": "Sliding Window",
      "contentMarkdown": "# Sliding Window\n\nA **Sliding Window** (ou *Janela Deslizante*) é uma técnica utilizada para otimizar algoritmos que trabalham com **subconjuntos contínuos de dados**, como listas ou arrays. Ela é amplamente usada em problemas de processamento de sequência, onde é necessário analisar partes do conjunto sem recalcular tudo a cada passo.\n\n\n## Conceito\n\nA técnica **Sliding Window** consiste em manter uma “janela” que se move sobre a estrutura de dados, processando apenas os elementos dentro dessa janela a cada iteração. Isso evita a repetição de cálculos, melhorando significativamente a eficiência.\n\nImagine que você quer calcular a soma de todos os subarrays de tamanho `k` em um array. Em vez de recalcular toda a soma para cada subarray, você pode **adicionar o próximo elemento** e **remover o primeiro da janela anterior**, economizando tempo.\n\nEssa técnica é comum em problemas de **média móvel**, **busca de subcadeias**, **detecção de padrões**, e **otimização de desempenho** em fluxos contínuos de dados.\n\n\n### Estrutura e Funcionamento\n\n- A janela tem um **tamanho fixo** (k) ou **variável**, dependendo do problema.  \n- Em cada passo:\n  1. O limite direito da janela avança (inclusão de um novo elemento).\n  2. O limite esquerdo pode ser movido (remoção de um elemento antigo).\n- O processamento é feito com base apenas nos elementos dentro da janela atual.\n\n\n![Ilustração da técnica Sliding Window em um array](https://i.postimg.cc/2y0bbb39/sliding-window.png)\n\n\n## Etapas do Algoritmo\n\n- **Inicialização:** Defina o tamanho da janela e os índices de início e fim.  \n- **Expansão:** Mova o final da janela para incluir novos elementos.  \n- **Atualização:** Atualize a métrica (soma, média, máximo etc.) com base na mudança da janela.  \n- **Contração (opcional):** Mova o início da janela quando necessário (por exemplo, quando o tamanho excede `k`).  \n- **Iteração:** Continue até o final do array.\n\n\n## Implementação (Python)\n\n```python\n# Exemplo: Soma máxima de uma subjanela de tamanho k\n\ndef max_sum_sliding_window(arr, k):\n    # Verifica se o tamanho da janela é válido\n    if len(arr) < k or k <= 0:\n        return 0\n\n    # Calcula a soma inicial da primeira janela\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n\n    # Move a janela da esquerda para a direita\n    for i in range(k, len(arr)):\n        # Atualiza a soma removendo o primeiro e adicionando o próximo elemento\n        window_sum += arr[i] - arr[i - k]\n        max_sum = max(max_sum, window_sum)\n\n    return max_sum\n\n# Exemplo de uso\narray = [2, 1, 5, 1, 3, 2]\nk = 3\nprint(\"Maior soma de uma janela de tamanho\", k, \":\", max_sum_sliding_window(array, k))\n```\n\n**Saída esperada:**  \n```\nMaior soma de uma janela de tamanho 3 : 9\n```\n\n\n## Vantagens e Desvantagens\n\n### ✅ Vantagens\n- Reduz o custo computacional de O(n*k) para **O(n)** em muitos casos.\n- Fácil de implementar e adaptar a diferentes problemas.\n- Ideal para dados contínuos e em tempo real.\n\n### ❌ Desvantagens\n- Requer que os dados estejam em uma sequência contínua.\n- Pode ser menos intuitivo em problemas com janelas de tamanho variável.\n- Nem todos os problemas se beneficiam dessa abordagem.\n\n\n## Uso e Aplicações\n\n- **Cálculo de médias móveis** (em séries temporais e sensores).  \n- **Análise de substrings** (como busca de padrões em texto).  \n- **Problemas de máximo/mínimo em intervalos fixos**.  \n- **Monitoramento de desempenho** em sistemas de streaming de dados.  \n- **Detecção de anomalias** em janelas de eventos recentes.\n\n\n## Complexidade\n\n- **Tempo:** O(n), pois cada elemento entra e sai da janela no máximo uma vez.  \n- **Espaço:** O(1) para janela fixa (ou O(k) para armazenar os elementos).\n\n\nA técnica **Sliding Window** é uma das mais poderosas em otimização de algoritmos que lidam com dados sequenciais, oferecendo eficiência e simplicidade na resolução de problemas práticos.\n"
    },
    {
      "name": "Binary Search",
      "contentMarkdown": "# Binary Search\n\nA **Busca Binária** é um algoritmo eficiente para encontrar um elemento em uma lista **ordenada**. Ela reduz pela metade o espaço de busca a cada iteração, tornando-a muito mais rápida do que a busca linear em listas grandes.\n\n## Conceito\n\nA ideia central da busca binária é dividir o problema repetidamente ao meio. Dado um array ordenado, o algoritmo compara o elemento do meio com o valor procurado:\n\n- Se o valor do meio for igual ao elemento buscado, o algoritmo termina.\n- Se o valor do meio for maior, a busca continua na metade esquerda.\n- Se o valor do meio for menor, a busca continua na metade direita.\n\nEsse processo se repete até encontrar o elemento ou até o intervalo de busca ficar vazio.\n\n### Estrutura do Algoritmo\n\nO algoritmo depende de três variáveis principais:\n\n- **início**: o índice inicial da busca.\n- **fim**: o índice final da busca.\n- **meio**: o ponto central entre início e fim.\n\n![Diagrama ilustrativo da Busca Binária](https://i.postimg.cc/KjG38rct/binary-search.png)\n\n## Etapas do Algoritmo\n\n- Definir os índices de início e fim.\n- Calcular o índice do meio: `(inicio + fim) // 2`.\n- Comparar o valor no meio com o elemento buscado.\n- Atualizar o intervalo (início/fim) conforme o resultado da comparação.\n- Repetir até encontrar o valor ou o intervalo ser inválido.\n\n## Implementação (Python)\n\n```python\ndef busca_binaria(lista, alvo):\n    inicio = 0\n    fim = len(lista) - 1\n\n    while inicio <= fim:\n        meio = (inicio + fim) // 2  # Calcula o índice do meio\n        if lista[meio] == alvo:\n            return meio  # Elemento encontrado, retorna o índice\n        elif lista[meio] < alvo:\n            inicio = meio + 1  # Busca na metade direita\n        else:\n            fim = meio - 1  # Busca na metade esquerda\n\n    return -1  # Elemento não encontrado\n\n# Exemplo de uso\ndados = [1, 3, 5, 7, 9, 11]\nprint(busca_binaria(dados, 7))  # Saída: 3\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Extremamente eficiente em listas grandes.\n- Complexidade logarítmica (cresce lentamente com o tamanho dos dados).\n- Fácil de implementar tanto de forma iterativa quanto recursiva.\n\n**Desvantagens:**\n- Requer que a lista esteja **ordenada**.\n- Ineficiente em listas pequenas ou dinâmicas (com inserções/remoções frequentes).\n\n## Uso e Aplicações\n\n- Pesquisa em **bancos de dados ordenados**.\n- **Algoritmos de busca** em árvores binárias de busca (BST).\n- Busca em **dicionários, catálogos, registros e logs**.\n- **Verificação de condições** em algoritmos de otimização (como busca binária em resposta).\n\n## Complexidade\n\n- **Melhor caso:** O(1) — elemento encontrado no primeiro teste.\n- **Caso médio:** O(log n).\n- **Pior caso:** O(log n).\n- **Complexidade espacial:** O(1) na versão iterativa e O(log n) na versão recursiva (por conta da pilha de chamadas).\n"
    },
    {
      "name": "Depth-first Search",
      "contentMarkdown": "# Busca em Profundidade (DFS)\n\nA **Busca em Profundidade (Depth-First Search - DFS)** é um algoritmo fundamental usado para percorrer ou buscar elementos em **grafos** e **árvores**. Ele segue uma estratégia de ir o mais fundo possível em um ramo antes de retroceder, explorando assim caminhos completos antes de explorar outros.\n\n## Como Funciona\n\nA DFS utiliza o princípio de **exploração profunda**: começa em um nó inicial e segue para um de seus vizinhos, depois para o vizinho desse vizinho, e assim por diante, até não haver mais nós a visitar. Quando atinge um ponto sem novos caminhos, o algoritmo **retrocede** (backtrack) para explorar caminhos alternativos ainda não visitados.\n\nEssa abordagem pode ser implementada de duas formas:\n- **Recursiva:** utilizando a pilha de chamadas da função.\n- **Iterativa:** utilizando uma **pilha (stack)** manualmente.\n\nA DFS é particularmente útil para detectar ciclos, encontrar componentes conectados, resolver labirintos e realizar ordenações topológicas.\n\n### Estrutura Conceitual\n\nA ideia básica é manter uma estrutura de dados (pilha) que armazene os nós a visitar. Cada nó é marcado como visitado para evitar revisitas, e o processo continua até que todos os nós tenham sido explorados.\n\n![Diagrama ilustrativo da DFS explorando um grafo](https://i.postimg.cc/mkmzzzhz/dfs.png)\n\n## Etapas do Algoritmo\n\n1. Escolher um nó inicial.\n2. Marcar o nó como **visitado**.\n3. Visitar recursivamente todos os **vizinhos não visitados**.\n4. Se não houver vizinhos disponíveis, **retroceder** ao nó anterior.\n5. Repetir até que todos os nós sejam visitados.\n\n## Implementação (Python)\n\n```python\n# Implementação simples de DFS em Python (usando recursão)\n\n# Grafo representado como um dicionário de listas\ngrafo = {\n    'A': ['B', 'C'],\n    'B': ['D', 'E'],\n    'C': ['F'],\n    'D': [],\n    'E': ['F'],\n    'F': []\n}\n\nvisitados = set()\n\ndef dfs(no):\n    # Marca o nó como visitado\n    print(no)\n    visitados.add(no)\n    \n    # Visita cada vizinho não visitado\n    for vizinho in grafo[no]:\n        if vizinho not in visitados:\n            dfs(vizinho)\n\n# Executa a DFS a partir do nó 'A'\ndfs('A')\n```\n\n**Saída esperada:**\n```\nA B D E F C\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Simples de implementar (especialmente de forma recursiva).\n- Usa menos memória que a BFS em grafos grandes e esparsos.\n- Útil para encontrar caminhos ou detectar ciclos.\n\n**Desvantagens:**\n- Pode ficar presa em ciclos se não houver controle de nós visitados.\n- Nem sempre encontra o caminho mais curto.\n\n## Uso e Aplicações\n\n- **Detecção de ciclos** em grafos direcionados e não direcionados.\n- **Busca em labirintos** e resolução de puzzles.\n- **Ordenação topológica** em grafos direcionados acíclicos.\n- **Análise de conectividade** em redes.\n- **Geração de árvores de profundidade** para IA ou jogos.\n\n## Complexidade\n\n- **Tempo:** O(V + E), onde **V** é o número de vértices e **E** é o número de arestas.\n- **Espaço:** O(V), devido à pilha de chamadas recursivas ou estrutura auxiliar.\n\n"
    },
    {
      "name": "Breadth-first Search",
      "contentMarkdown": "# Busca em Largura (BFS)\n\nA **Busca em Largura** (Breadth-First Search - BFS) é um algoritmo de\n**traversal** (percurso) usado para explorar todos os vértices de um\ngrafo ou árvore **nível por nível**. É amplamente utilizado para\nencontrar o **menor caminho** em grafos não ponderados e verificar\n**conectividade** entre nós.\n\n## Como Funciona\n\nA BFS começa em um nó inicial (ou raiz) e visita **todos os nós vizinhos\ndiretamente conectados** antes de avançar para os vizinhos desses nós.\nIsso é feito usando uma **fila (queue)**, garantindo que os nós sejam\nexplorados em ordem de descoberta.\n\nA ideia principal é: **visitar primeiro os nós mais próximos** do ponto\nde partida e, depois, os mais distantes.\n\n### Estrutura Interna\n\nA BFS utiliza: - **Fila (queue):** para controlar a ordem de visita dos\nnós. - **Conjunto ou lista de visitados:** para evitar revisitar nós. -\n**Grafo (ou matriz de adjacência):** para armazenar as conexões entre\nnós.\n\n![Diagrama ilustrativo da\nBFS](https://i.postimg.cc/prW5LYVz/bfs.png)\n\n## Etapas do Algoritmo\n\n1.  Escolher um nó inicial e marcá-lo como visitado.\\\n2.  Inserir o nó na **fila**.\\\n3.  Enquanto a fila não estiver vazia:\n    -   Remover o primeiro nó da fila.\\\n    -   Visitar todos os seus vizinhos não visitados.\\\n    -   Adicionar esses vizinhos à fila e marcá-los como visitados.\n\n## Implementação (Python)\n\n``` python\nfrom collections import deque\n\ndef bfs(grafo, inicio):\n    visitados = set()            # Conjunto de nós já visitados\n    fila = deque([inicio])       # Fila com o nó inicial\n    visitados.add(inicio)\n\n    while fila:\n        no_atual = fila.popleft()     # Remove o primeiro nó da fila\n        print(no_atual, end=\" \")      # Processa o nó atual (ex: imprime)\n\n        # Visita os vizinhos do nó atual\n        for vizinho in grafo[no_atual]:\n            if vizinho not in visitados:\n                visitados.add(vizinho)\n                fila.append(vizinho)\n\n# Exemplo de uso\ngrafo = {\n    'A': ['B', 'C'],\n    'B': ['D', 'E'],\n    'C': ['F'],\n    'D': [],\n    'E': ['F'],\n    'F': []\n}\n\nbfs(grafo, 'A')\n# Saída esperada: A B C D E F\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:** \n- Garante o **menor caminho** em grafos não ponderados. \n- Simples de implementar. \n- Ideal para **buscas em largura** (nível por\nnível).\n\n**Desvantagens:** \n- Pode consumir **muita memória**, pois armazena\nmúltiplos nós na fila. \n- Não funciona bem em grafos **muito grandes**\nsem otimizações.\n\n## Uso e Aplicações\n\n-   Encontrar o **menor caminho** em grafos não ponderados.\n-   Verificar **conectividade** entre nós.\n-   Resolver **puzzles** (como o Cubo de Rubik ou labirintos).\n-   Sistemas de recomendação e **propagação de informação** em redes\n    sociais.\n\n## Complexidade\n\n-   **Tempo:** O(V + E), onde V é o número de vértices e E o número de\n    arestas.\\\n-   **Espaço:** O(V), devido à fila e ao conjunto de visitados.\n"
    },
    {
      "name": "Backtracking",
      "contentMarkdown": "# Backtracking\n\nO **Backtracking** é uma técnica de **busca e construção de soluções** utilizada em problemas onde é necessário explorar múltiplas possibilidades, retrocedendo quando um caminho não leva a uma solução válida. É muito usado em problemas combinatórios, de otimização e de decisão, como **sudoku, labirintos, permutações** e **subconjuntos**.\n\n## Como Funciona\n\nO Backtracking funciona de forma **recursiva**, tentando construir uma solução **passo a passo**. A cada passo, o algoritmo escolhe uma opção e avança. Caso essa escolha leve a um caminho inválido, ele **retrocede (backtrack)** para o ponto anterior e tenta outra opção.\n\nÉ como explorar um labirinto: você segue um caminho até encontrar uma parede; então volta ao último cruzamento e tenta outro caminho. O processo continua até encontrar uma saída ou esgotar todas as possibilidades.\n\n### Estrutura do Processo\n\n1. **Escolha:** selecione uma opção possível.\n2. **Restrição:** verifique se a escolha é válida.\n3. **Meta:** verifique se a solução foi encontrada.\n4. **Backtrack:** caso contrário, volte e tente outra opção.\n\n![Diagrama ilustrativo de Backtracking](https://i.postimg.cc/WzNq16pM/backtracking.png)\n\n## Etapas do Algoritmo\n\n- Escolher uma opção inicial.\n- Verificar se a opção atual é válida (respeita as restrições).\n- Se for válida, avançar para a próxima etapa.\n- Se não for válida, retornar (backtrack) e escolher outra alternativa.\n- Continuar até encontrar uma solução completa ou esgotar as possibilidades.\n\n## Implementação (Python)\n\n```python\n# Exemplo simples de Backtracking: todas as permutações de uma lista\n\ndef permutacoes(nums):\n    resultado = []\n\n    def backtrack(caminho, restantes):\n        # Caso base: se não há mais elementos, adiciona a permutação completa\n        if not restantes:\n            resultado.append(caminho[:])\n            return\n\n        # Tenta cada opção possível\n        for i in range(len(restantes)):\n            # Escolhe o elemento atual\n            caminho.append(restantes[i])\n            # Continua com os elementos restantes\n            backtrack(caminho, restantes[:i] + restantes[i+1:])\n            # Retrocede (remove o último elemento)\n            caminho.pop()\n\n    backtrack([], nums)\n    return resultado\n\n# Exemplo de uso\nprint(permutacoes([1, 2, 3]))\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Encontra todas as soluções possíveis.\n- Fácil de implementar usando recursão.\n- Pode ser otimizado com **poda (pruning)** para evitar caminhos inúteis.\n\n**Desvantagens:**\n- Pode ser **muito lento** (explora muitas combinações).\n- O consumo de memória cresce rapidamente em casos grandes.\n- Ineficiente para problemas com grande número de possibilidades.\n\n## Uso e Aplicações\n\n- Resolver **Sudoku** e **labirintos**.\n- Gerar **permutação e combinação** de elementos.\n- Resolver o **problema das N rainhas**.\n- Construir **subconjuntos** e **partições**.\n- Planejamento e busca em **inteligência artificial**.\n\n## Complexidade\n\nA complexidade de tempo depende do número de combinações possíveis.  \nEm geral, o pior caso é **exponencial**, tipicamente **O(b^d)**, onde:\n- **b** é o número médio de escolhas por passo.\n- **d** é a profundidade da árvore de recursão.\n\nA complexidade de espaço é **O(d)**, correspondente à profundidade da pilha de recursão.\n"
    },
    {
      "name": "Array",
      "contentMarkdown": "# Arrays\n\nOs **Arrays** são estruturas de dados lineares que armazenam um conjunto de elementos do **mesmo tipo** em posições contíguas de memória. Eles permitem o acesso direto a qualquer elemento por meio de seu **índice**, o que os torna extremamente eficientes para leituras e buscas por posição.\n\n\n## Conceito\n\nUm **Array** funciona como uma sequência ordenada de elementos, onde cada posição é identificada por um índice numérico.  \nPor exemplo, um array de inteiros pode armazenar `[10, 20, 30, 40]`, onde o índice `0` representa o valor `10`, o índice `1` o valor `20`, e assim por diante.\n\nEm termos práticos, podemos pensar em um array como uma **prateleira de caixas**, onde cada caixa guarda um valor e todas estão alinhadas lado a lado, facilitando o acesso a qualquer uma delas rapidamente.\n\n\n## Estrutura Interna\n\nCada elemento em um array é armazenado em posições consecutivas de memória.  \nSe o primeiro elemento ocupa a posição de memória `x`, e cada elemento ocupa `k` bytes, o próximo elemento estará na posição `x + k`, e o seguinte em `x + 2k`, e assim sucessivamente.\n\nEssa organização permite o **acesso direto (O(1))** a qualquer elemento, já que o endereço pode ser calculado diretamente a partir do índice.\n\n\n![Diagrama ilustrativo de um Array](https://i.postimg.cc/x8fN1yjc/arrays.png)\n\n\n## Operações Comuns\n\n- **Acesso:** Recupera o valor de um elemento a partir do índice.  \n- **Atualização:** Modifica o valor armazenado em uma posição específica.  \n- **Inserção:** Adiciona um novo elemento (pode exigir deslocar elementos se não houver espaço).  \n- **Remoção:** Exclui um elemento e pode exigir o deslocamento dos demais.  \n- **Busca:** Encontra um elemento específico (geralmente O(n) se não houver ordenação).  \n- **Percorrimento:** Itera por todos os elementos do array.\n\n\n## Implementação (Python)\n\n```python\n# Criação de um array (em Python, usamos listas para esse propósito)\narray = [10, 20, 30, 40]\n\n# Acesso a elementos pelo índice\nprint(\"Primeiro elemento:\", array[0])  # Saída: 10\n\n# Atualização de um valor\narray[1] = 25\nprint(\"Após atualização:\", array)  # Saída: [10, 25, 30, 40]\n\n# Inserção de novo elemento\narray.append(50)\nprint(\"Após inserção:\", array)  # Saída: [10, 25, 30, 40, 50]\n\n# Remoção de elemento\narray.remove(30)\nprint(\"Após remoção:\", array)  # Saída: [10, 25, 40, 50]\n\n# Percorrimento do array\nfor elemento in array:\n    print(\"Elemento:\", elemento)\n```\n\n\n## Vantagens\n\n- **Acesso rápido (O(1))** a qualquer elemento via índice.  \n- **Estrutura simples** e de fácil implementação.  \n- **Melhor uso da memória cache**, pois os elementos são contíguos na memória.\n\n\n## Desvantagens\n\n- **Tamanho fixo:** não pode ser alterado após a criação (em linguagens como C).  \n- **Inserções e remoções caras (O(n))**, pois exigem deslocamento dos elementos.  \n- **Todos os elementos devem ser do mesmo tipo** (em linguagens fortemente tipadas).\n\n\n## Uso e Aplicações\n\n- Armazenar listas de valores fixos, como notas, temperaturas ou IDs.  \n- Implementar estruturas mais complexas como **matrizes**, **filas** e **pilhas**.  \n- Processamento de dados em **algoritmos de ordenação e busca**.  \n- Uso em **sistemas embarcados** onde o tamanho é conhecido e fixo.\n\n\n## Complexidade\n\n| Operação        | Complexidade de Tempo | Complexidade de Espaço |\n|------------------|-----------------------|--------------------------|\n| Acesso           | O(1)                  | O(n)                     |\n| Atualização      | O(1)                  | O(n)                     |\n| Inserção         | O(n)                  | O(n)                     |\n| Remoção          | O(n)                  | O(n)                     |\n| Busca Linear     | O(n)                  | O(n)                     |\n\n\nEm resumo, os **arrays** são fundamentais em Estruturas de Dados, servindo como base para muitas outras abstrações e algoritmos. Seu principal ponto forte é o acesso direto e eficiente, embora tenham limitações de flexibilidade em tamanho e operações de modificação.\n"
    },
    {
      "name": "Linked List",
      "contentMarkdown": "# Linked List (Lista Encadeada)\n\nAs **Linked Lists** (ou **Listas Encadeadas**) são estruturas de dados lineares compostas por uma sequência de **nós** conectados entre si por meio de **referências (ponteiros)**. Diferente dos arrays, os elementos não são armazenados de forma contígua na memória, permitindo inserções e remoções eficientes em qualquer posição.\n\n## Conceito\n\nUma **lista encadeada** funciona como uma cadeia de elementos, onde cada nó armazena dois dados principais:\n- **O valor (dados)**\n- **Uma referência (ponteiro)** para o próximo nó da lista\n\nO último nó da lista aponta para `None` (ou `NULL` em C), indicando o final da sequência.  \nEssa estrutura é ideal quando o tamanho da lista pode variar dinamicamente, pois não requer alocação de blocos de memória contínuos.\n\n**Analogia:** imagine um conjunto de vagões de trem — cada vagão (nó) carrega uma carga (dado) e está ligado ao próximo por um engate (ponteiro).\n\n## Estrutura Interna\n\nCada **nó (Node)** da lista contém:\n- `valor`: o dado armazenado\n- `next`: referência para o próximo nó\n\nA **lista em si** mantém uma referência para o **primeiro nó (head)**, e opcionalmente, para o **último nó (tail)** em versões otimizadas.\n\n![Diagrama ilustrativo de uma Linked List](https://i.postimg.cc/vT0gggD7/lista-ligada.png)\n\n## Operações Comuns\n\n- **Inserção:** adicionar um novo nó no início, fim ou meio da lista.  \n- **Remoção:** eliminar um nó específico.  \n- **Busca:** percorrer a lista até encontrar um valor.  \n- **Travessia:** visitar cada nó da lista em sequência.  \n\n## Implementação (Python)\n\n```python\n# Implementação simples de uma Linked List em Python\n\n# Classe que representa um nó da lista\nclass Node:\n    def __init__(self, valor):\n        self.valor = valor    # Dado armazenado no nó\n        self.next = None      # Ponteiro para o próximo nó\n\n# Classe que representa a Linked List\nclass LinkedList:\n    def __init__(self):\n        self.head = None  # Início da lista (vazia)\n\n    # Adiciona um elemento ao final da lista\n    def append(self, valor):\n        novo_no = Node(valor)\n        if self.head is None:\n            self.head = novo_no\n            return\n        atual = self.head\n        while atual.next:\n            atual = atual.next\n        atual.next = novo_no\n\n    # Exibe os elementos da lista\n    def mostrar(self):\n        atual = self.head\n        while atual:\n            print(atual.valor, end=\" -> \")\n            atual = atual.next\n        print(\"None\")\n\n# Exemplo de uso\nlista = LinkedList()\nlista.append(10)\nlista.append(20)\nlista.append(30)\nlista.mostrar()  # Saída: 10 -> 20 -> 30 -> None\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Inserções e remoções são rápidas (O(1)) quando se tem a referência do nó.  \n- Não requer memória contígua.  \n- Tamanho da lista pode crescer dinamicamente.  \n\n**Desvantagens:**\n- Acesso a elementos é sequencial (O(n)), não é possível acessar diretamente por índice.  \n- Uso adicional de memória por conta dos ponteiros.  \n- Mais complexa de implementar e manipular que arrays.  \n\n## Uso e Aplicações\n\n- Implementação de **pilhas (stacks)** e **filas (queues)**.  \n- Gerenciamento de **memória dinâmica**.  \n- Estruturas como **hash tables** (listas de colisão) e **gráfos**.  \n- Situações em que há **muitas inserções e remoções** durante a execução.  \n\n## Complexidade\n\n| Operação | Tempo Médio | Tempo Pior Caso |\n|-----------|--------------|----------------|\n| Inserção no início | O(1) | O(1) |\n| Inserção no fim | O(n) | O(n) |\n| Remoção | O(n) | O(n) |\n| Busca | O(n) | O(n) |\n| Espaço | O(n) | O(n) |\n\nEm resumo, **Linked Lists** oferecem flexibilidade em cenários dinâmicos, com custo de acesso mais alto em comparação aos arrays.\n"
    },
    {
      "name": "Stack",
      "contentMarkdown": "# Stack (Pilha)\n\nUma **Stack** (pilha) é uma estrutura de dados linear que segue o princípio **LIFO** (Last In, First Out - Último a Entrar, Primeiro a Sair). Isso significa que o último elemento adicionado à pilha será o primeiro a ser removido, como uma pilha de pratos onde você sempre adiciona e remove pratos do topo.\n\n## Como Funciona\n\nA pilha funciona através de um ponto de acesso único chamado **topo** (top). Todas as operações de inserção e remoção acontecem exclusivamente neste ponto. Imagine uma pilha de livros: você só pode adicionar um novo livro no topo e só pode remover o livro que está no topo. Não é possível acessar ou remover elementos do meio ou da base sem antes remover todos os elementos acima deles.\n\nO conceito de **LIFO** é fundamental para entender o comportamento da pilha. Quando você adiciona elementos sequencialmente (1, 2, 3), o elemento 3 será o primeiro a ser removido, depois o 2, e por último o 1. Esta característica torna as pilhas ideais para cenários onde a ordem de processamento inversa é necessária.\n\n### Estrutura e Componentes\n\nUma pilha é composta basicamente por:\n\n* **Topo (Top):** Ponteiro ou referência que indica o elemento no topo da pilha\n* **Capacidade (Capacity):** Tamanho máximo da pilha (em implementações com array)\n* **Tamanho (Size):** Quantidade atual de elementos na pilha\n* **Elementos:** Os dados armazenados na estrutura\n\n![Diagrama ilustrativo de uma Stack mostrando operações push e pop](https://i.postimg.cc/8cZJJJsB/pilha.png)\n\n## Operações Comuns\n\n* **Push (Empilhar):** Adiciona um elemento no topo da pilha\n* **Pop (Desempilhar):** Remove e retorna o elemento do topo da pilha\n* **Peek/Top (Espiar):** Retorna o elemento do topo sem removê-lo\n* **isEmpty (Está Vazia):** Verifica se a pilha está vazia\n* **isFull (Está Cheia):** Verifica se a pilha atingiu sua capacidade máxima (em implementações com tamanho fixo)\n* **Size (Tamanho):** Retorna a quantidade de elementos na pilha\n\n## Implementação (Python)\n\n```python\nclass Stack:\n    def __init__(self):\n        \"\"\"Inicializa uma pilha vazia\"\"\"\n        self.items = []\n    \n    def push(self, item):\n        \"\"\"Adiciona um elemento no topo da pilha\"\"\"\n        self.items.append(item)\n    \n    def pop(self):\n        \"\"\"Remove e retorna o elemento do topo\"\"\"\n        if not self.is_empty():\n            return self.items.pop()\n        raise IndexError(\"Pop de uma pilha vazia\")\n    \n    def peek(self):\n        \"\"\"Retorna o elemento do topo sem remover\"\"\"\n        if not self.is_empty():\n            return self.items[-1]\n        raise IndexError(\"Peek de uma pilha vazia\")\n    \n    def is_empty(self):\n        \"\"\"Verifica se a pilha está vazia\"\"\"\n        return len(self.items) == 0\n    \n    def size(self):\n        \"\"\"Retorna o tamanho da pilha\"\"\"\n        return len(self.items)\n\n# Exemplo de uso\npilha = Stack()\npilha.push(10)\npilha.push(20)\npilha.push(30)\n\nprint(f\"Topo: {pilha.peek()}\")  # Saída: Topo: 30\nprint(f\"Removido: {pilha.pop()}\")  # Saída: Removido: 30\nprint(f\"Tamanho: {pilha.size()}\")  # Saída: Tamanho: 2\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n* Operações de inserção e remoção muito rápidas: O(1)\n* Implementação simples e intuitiva\n* Gerenciamento eficiente de memória em chamadas de função\n* Ideal para rastreamento de estados e reversão de operações\n* Estrutura natural para problemas recursivos\n\n**Desvantagens:**\n\n* Acesso restrito: só é possível acessar o elemento do topo\n* Não permite busca eficiente de elementos no meio da pilha\n* Tamanho limitado em implementações com array fixo\n* Não é adequada quando é necessário acesso aleatório aos elementos\n\n## Uso e Aplicações\n\n* **Gerenciamento de chamadas de função:** A pilha de execução (call stack) armazena informações sobre funções ativas\n* **Avaliação de expressões:** Conversão e cálculo de expressões matemáticas (notação infixa para pós-fixa)\n* **Undo/Redo em editores:** Cada ação é empilhada e pode ser desfeita na ordem inversa\n* **Navegação de histórico:** Botões \"voltar\" e \"avançar\" em navegadores web\n* **Verificação de balanceamento:** Validação de parênteses, chaves e colchetes em código\n* **Algoritmos de backtracking:** Resolução de labirintos, sudoku e problemas de busca\n* **Parsing e compiladores:** Análise sintática de linguagens de programação\n* **Inversão de dados:** Reverter strings ou sequências\n\n## Complexidade\n\n| Operação   | Tempo   | Espaço   |\n|------------|---------|----------|\n| Push       | O(1)    | O(n)     |\n| Pop        | O(1)    | O(n)     |\n| Peek/Top   | O(1)    | O(n)     |\n| Search     | O(n)    | O(n)     |\n\n- **Tempo:** Refere-se ao tempo necessário para executar cada operação.\n- **Espaço:** Refere-se ao espaço de memória ocupado pela pilha, proporcional ao número de elementos n.\n\nA eficiência das operações principais (push, pop e peek) em tempo constante torna a pilha uma estrutura de dados extremamente útil para diversos cenários onde o acesso sequencial inverso é necessário."
    }
  ],
  "page": 1,
  "size": 10,
  "totalElements": 68,
  "totalPages": 7,
  "first": false,
  "last": false
}