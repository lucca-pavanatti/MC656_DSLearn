{
  "content": [
    {
      "name": "Array",
      "contentMarkdown": "# Arrays contentMarkdown"
    },
    {
      "name": "Linked List",
      "contentMarkdown": "# Linked List (Lista Encadeada)\n\nAs **Linked Lists** (ou **Listas Encadeadas**) são estruturas de dados lineares compostas por uma sequência de **nós** conectados entre si por meio de **referências (ponteiros)**. Diferente dos arrays, os elementos não são armazenados de forma contígua na memória, permitindo inserções e remoções eficientes em qualquer posição.\n\n## Conceito\n\nUma **lista encadeada** funciona como uma cadeia de elementos, onde cada nó armazena dois dados principais:\n- **O valor (dados)**\n- **Uma referência (ponteiro)** para o próximo nó da lista\n\nO último nó da lista aponta para `None` (ou `NULL` em C), indicando o final da sequência.  \nEssa estrutura é ideal quando o tamanho da lista pode variar dinamicamente, pois não requer alocação de blocos de memória contínuos.\n\n**Analogia:** imagine um conjunto de vagões de trem — cada vagão (nó) carrega uma carga (dado) e está ligado ao próximo por um engate (ponteiro).\n\n## Estrutura Interna\n\nCada **nó (Node)** da lista contém:\n- `valor`: o dado armazenado\n- `next`: referência para o próximo nó\n\nA **lista em si** mantém uma referência para o **primeiro nó (head)**, e opcionalmente, para o **último nó (tail)** em versões otimizadas.\n\n![Diagrama ilustrativo de uma Linked List](https://i.postimg.cc/vT0gggD7/lista-ligada.png)\n\n## Operações Comuns\n\n- **Inserção:** adicionar um novo nó no início, fim ou meio da lista.  \n- **Remoção:** eliminar um nó específico.  \n- **Busca:** percorrer a lista até encontrar um valor.  \n- **Travessia:** visitar cada nó da lista em sequência.  \n\n## Implementação (Python)\n\n```python\n# Implementação simples de uma Linked List em Python\n\n# Classe que representa um nó da lista\nclass Node:\n    def __init__(self, valor):\n        self.valor = valor    # Dado armazenado no nó\n        self.next = None      # Ponteiro para o próximo nó\n\n# Classe que representa a Linked List\nclass LinkedList:\n    def __init__(self):\n        self.head = None  # Início da lista (vazia)\n\n    # Adiciona um elemento ao final da lista\n    def append(self, valor):\n        novo_no = Node(valor)\n        if self.head is None:\n            self.head = novo_no\n            return\n        atual = self.head\n        while atual.next:\n            atual = atual.next\n        atual.next = novo_no\n\n    # Exibe os elementos da lista\n    def mostrar(self):\n        atual = self.head\n        while atual:\n            print(atual.valor, end=\" -> \")\n            atual = atual.next\n        print(\"None\")\n\n# Exemplo de uso\nlista = LinkedList()\nlista.append(10)\nlista.append(20)\nlista.append(30)\nlista.mostrar()  # Saída: 10 -> 20 -> 30 -> None\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Inserções e remoções são rápidas (O(1)) quando se tem a referência do nó.  \n- Não requer memória contígua.  \n- Tamanho da lista pode crescer dinamicamente.  \n\n**Desvantagens:**\n- Acesso a elementos é sequencial (O(n)), não é possível acessar diretamente por índice.  \n- Uso adicional de memória por conta dos ponteiros.  \n- Mais complexa de implementar e manipular que arrays.  \n\n## Uso e Aplicações\n\n- Implementação de **pilhas (stacks)** e **filas (queues)**.  \n- Gerenciamento de **memória dinâmica**.  \n- Estruturas como **hash tables** (listas de colisão) e **gráfos**.  \n- Situações em que há **muitas inserções e remoções** durante a execução.  \n\n## Complexidade\n\n| Operação | Tempo Médio | Tempo Pior Caso |\n|-----------|--------------|----------------|\n| Inserção no início | O(1) | O(1) |\n| Inserção no fim | O(n) | O(n) |\n| Remoção | O(n) | O(n) |\n| Busca | O(n) | O(n) |\n| Espaço | O(n) | O(n) |\n\nEm resumo, **Linked Lists** oferecem flexibilidade em cenários dinâmicos, com custo de acesso mais alto em comparação aos arrays.\n"
    },
    {
      "name": "Stack",
      "contentMarkdown": "# Stack (Pilha)\n\nUma **Stack** (pilha) é uma estrutura de dados linear que segue o princípio **LIFO** (Last In, First Out - Último a Entrar, Primeiro a Sair). Isso significa que o último elemento adicionado à pilha será o primeiro a ser removido, como uma pilha de pratos onde você sempre adiciona e remove pratos do topo.\n\n## Como Funciona\n\nA pilha funciona através de um ponto de acesso único chamado **topo** (top). Todas as operações de inserção e remoção acontecem exclusivamente neste ponto. Imagine uma pilha de livros: você só pode adicionar um novo livro no topo e só pode remover o livro que está no topo. Não é possível acessar ou remover elementos do meio ou da base sem antes remover todos os elementos acima deles.\n\nO conceito de **LIFO** é fundamental para entender o comportamento da pilha. Quando você adiciona elementos sequencialmente (1, 2, 3), o elemento 3 será o primeiro a ser removido, depois o 2, e por último o 1. Esta característica torna as pilhas ideais para cenários onde a ordem de processamento inversa é necessária.\n\n### Estrutura e Componentes\n\nUma pilha é composta basicamente por:\n\n* **Topo (Top):** Ponteiro ou referência que indica o elemento no topo da pilha\n* **Capacidade (Capacity):** Tamanho máximo da pilha (em implementações com array)\n* **Tamanho (Size):** Quantidade atual de elementos na pilha\n* **Elementos:** Os dados armazenados na estrutura\n\n![Diagrama ilustrativo de uma Stack mostrando operações push e pop](https://i.postimg.cc/8cZJJJsB/pilha.png)\n\n## Operações Comuns\n\n* **Push (Empilhar):** Adiciona um elemento no topo da pilha\n* **Pop (Desempilhar):** Remove e retorna o elemento do topo da pilha\n* **Peek/Top (Espiar):** Retorna o elemento do topo sem removê-lo\n* **isEmpty (Está Vazia):** Verifica se a pilha está vazia\n* **isFull (Está Cheia):** Verifica se a pilha atingiu sua capacidade máxima (em implementações com tamanho fixo)\n* **Size (Tamanho):** Retorna a quantidade de elementos na pilha\n\n## Implementação (Python)\n\n```python\nclass Stack:\n    def __init__(self):\n        \"\"\"Inicializa uma pilha vazia\"\"\"\n        self.items = []\n    \n    def push(self, item):\n        \"\"\"Adiciona um elemento no topo da pilha\"\"\"\n        self.items.append(item)\n    \n    def pop(self):\n        \"\"\"Remove e retorna o elemento do topo\"\"\"\n        if not self.is_empty():\n            return self.items.pop()\n        raise IndexError(\"Pop de uma pilha vazia\")\n    \n    def peek(self):\n        \"\"\"Retorna o elemento do topo sem remover\"\"\"\n        if not self.is_empty():\n            return self.items[-1]\n        raise IndexError(\"Peek de uma pilha vazia\")\n    \n    def is_empty(self):\n        \"\"\"Verifica se a pilha está vazia\"\"\"\n        return len(self.items) == 0\n    \n    def size(self):\n        \"\"\"Retorna o tamanho da pilha\"\"\"\n        return len(self.items)\n\n# Exemplo de uso\npilha = Stack()\npilha.push(10)\npilha.push(20)\npilha.push(30)\n\nprint(f\"Topo: {pilha.peek()}\")  # Saída: Topo: 30\nprint(f\"Removido: {pilha.pop()}\")  # Saída: Removido: 30\nprint(f\"Tamanho: {pilha.size()}\")  # Saída: Tamanho: 2\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n* Operações de inserção e remoção muito rápidas: O(1)\n* Implementação simples e intuitiva\n* Gerenciamento eficiente de memória em chamadas de função\n* Ideal para rastreamento de estados e reversão de operações\n* Estrutura natural para problemas recursivos\n\n**Desvantagens:**\n\n* Acesso restrito: só é possível acessar o elemento do topo\n* Não permite busca eficiente de elementos no meio da pilha\n* Tamanho limitado em implementações com array fixo\n* Não é adequada quando é necessário acesso aleatório aos elementos\n\n## Uso e Aplicações\n\n* **Gerenciamento de chamadas de função:** A pilha de execução (call stack) armazena informações sobre funções ativas\n* **Avaliação de expressões:** Conversão e cálculo de expressões matemáticas (notação infixa para pós-fixa)\n* **Undo/Redo em editores:** Cada ação é empilhada e pode ser desfeita na ordem inversa\n* **Navegação de histórico:** Botões \"voltar\" e \"avançar\" em navegadores web\n* **Verificação de balanceamento:** Validação de parênteses, chaves e colchetes em código\n* **Algoritmos de backtracking:** Resolução de labirintos, sudoku e problemas de busca\n* **Parsing e compiladores:** Análise sintática de linguagens de programação\n* **Inversão de dados:** Reverter strings ou sequências\n\n## Complexidade\n\n| Operação   | Tempo   | Espaço   |\n|------------|---------|----------|\n| Push       | O(1)    | O(n)     |\n| Pop        | O(1)    | O(n)     |\n| Peek/Top   | O(1)    | O(n)     |\n| Search     | O(n)    | O(n)     |\n\n- **Tempo:** Refere-se ao tempo necessário para executar cada operação.\n- **Espaço:** Refere-se ao espaço de memória ocupado pela pilha, proporcional ao número de elementos n.\n\nA eficiência das operações principais (push, pop e peek) em tempo constante torna a pilha uma estrutura de dados extremamente útil para diversos cenários onde o acesso sequencial inverso é necessário."
    },
    {
      "name": "Queue",
      "contentMarkdown": "# Queue (Fila)\n\nUma **Queue** (ou **Fila**) é uma estrutura de dados linear que segue o princípio **FIFO (First In, First Out)** — o primeiro elemento inserido é o primeiro a ser removido. Ela é amplamente utilizada em sistemas onde a ordem de chegada dos elementos deve ser preservada, como filas de impressão, requisições em servidores ou buffers de mensagens.\n\n## Como Funciona\n\nEm uma fila, os elementos são inseridos **no final (enqueue)** e removidos **do início (dequeue)**. Isso garante que o primeiro elemento adicionado seja o primeiro processado.  \nPodemos imaginar uma fila de pessoas esperando para serem atendidas: quem chega primeiro é atendido primeiro.\n\n### Estrutura Interna\n\nUma fila pode ser implementada de várias formas:\n- Usando **listas** (arrays dinâmicos);\n- Usando **ponteiros**, como em **listas ligadas**;\n- Através de **estruturas otimizadas**, como `collections.deque` em Python, que oferece operações O(1) para inserção e remoção.\n\n![Diagrama ilustrativo de uma fila FIFO](https://i.postimg.cc/Hn6cccj8/fila.png)\n\n## Operações Comuns\n\n- **Enqueue (inserção):** adiciona um elemento ao final da fila.\n- **Dequeue (remoção):** remove o elemento do início da fila.\n- **Front (ou Peek):** retorna o primeiro elemento sem removê-lo.\n- **IsEmpty:** verifica se a fila está vazia.\n- **Size:** retorna o número de elementos na fila.\n\n## Implementação (Python)\n\nA seguir, um exemplo simples de implementação de uma fila usando `collections.deque`:\n\n```python\nfrom collections import deque\n\nclass Queue:\n    def __init__(self):\n        self.items = deque()\n\n    def is_empty(self):\n        # Retorna True se a fila estiver vazia\n        return len(self.items) == 0\n\n    def enqueue(self, item):\n        # Adiciona um elemento ao final da fila\n        self.items.append(item)\n\n    def dequeue(self):\n        # Remove e retorna o elemento do início da fila\n        if not self.is_empty():\n            return self.items.popleft()\n        return None\n\n    def peek(self):\n        # Retorna o primeiro elemento sem removê-lo\n        if not self.is_empty():\n            return self.items[0]\n        return None\n\n    def size(self):\n        # Retorna o número de elementos na fila\n        return len(self.items)\n\n\n# Exemplo de uso\nfila = Queue()\nfila.enqueue(\"A\")\nfila.enqueue(\"B\")\nfila.enqueue(\"C\")\n\nprint(\"Primeiro da fila:\", fila.peek())  # A\nprint(\"Removendo:\", fila.dequeue())      # A\nprint(\"Novo primeiro:\", fila.peek())     # B\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Mantém a ordem de chegada dos elementos.\n- Fácil de implementar e compreender.\n- Útil em sistemas de processamento sequencial.\n\n**Desvantagens:**\n- Acesso restrito (somente início e fim).\n- Pode exigir realocação de memória se implementada com arrays simples.\n\n## Uso e Aplicações\n\n- **Sistemas de atendimento** (filas de espera, impressoras).\n- **Processamento de tarefas em background** (job queues).\n- **Estruturas de controle em algoritmos BFS (Breadth-First Search)**.\n- **Buffers de comunicação** entre processos ou threads.\n\n## Complexidade\n\n| Operação  | Tempo Médio | Descrição |\n|------------|--------------|------------|\n| Enqueue    | O(1)         | Inserção no final da fila |\n| Dequeue    | O(1)         | Remoção no início da fila |\n| Peek       | O(1)         | Acesso ao primeiro elemento |\n| IsEmpty    | O(1)         | Verificação de estado |\n| Size       | O(1)         | Retorna o tamanho da fila |\n| Espaço     | O(n)         | Armazena n elementos |\n"
    },
    {
      "name": "Tree",
      "contentMarkdown": "# Tree (Árvore)\n\nUma **Tree** (ou **Árvore**) é uma estrutura de dados hierárquica composta por **nós (nodes)**, onde cada nó armazena um valor e referências para outros nós chamados de **filhos (children)**. Ela é amplamente usada para representar relações hierárquicas, como sistemas de arquivos, estruturas de diretórios e árvores de decisão.\n\n## Conceito\n\nA **árvore** segue uma estrutura onde existe um **nó raiz (root)** no topo, que se ramifica em **subárvores** menores. Cada nó pode ter **zero ou mais filhos**, e um nó sem filhos é chamado de **folha (leaf)**.  \nNão existem ciclos — ou seja, não há caminhos que levem de volta a um nó anterior.\n\nUma boa analogia é a **árvore genealógica**: um ancestral (raiz) possui filhos, que por sua vez podem ter seus próprios filhos, e assim por diante.\n\n### Estrutura da Árvore\n\n- **Root (raiz):** primeiro nó da árvore.\n- **Parent (pai):** nó que possui filhos.\n- **Child (filho):** nó descendente de outro nó.\n- **Leaf (folha):** nó sem filhos.\n- **Edge (aresta):** conexão entre dois nós.\n- **Height (altura):** comprimento do maior caminho da raiz até uma folha.\n\n![Diagrama ilustrativo de uma árvore binária](https://i.postimg.cc/2y0bbb3H/tree.png)\n\n## Tipos Comuns de Árvores\n\n- **Árvore Binária:** cada nó tem no máximo dois filhos (esquerdo e direito).\n- **Árvore Binária de Busca (BST):** os nós à esquerda contêm valores menores e à direita, maiores.\n- **Árvore Balanceada:** mantém altura próxima entre subárvores (ex: AVL, Red-Black).\n- **Árvore Genérica:** nós podem ter qualquer número de filhos.\n- **Árvore Trie:** usada para armazenar strings, comum em autocomplete e dicionários.\n\n## Operações Comuns\n\n- **Inserção:** adiciona um novo nó à árvore.\n- **Busca:** procura um elemento específico.\n- **Remoção:** exclui um nó mantendo a estrutura da árvore.\n- **Travessias (Traversals):**\n  - **Pre-order:** processa o nó antes dos filhos.\n  - **In-order:** processa o nó entre os filhos (esquerda → raiz → direita).\n  - **Post-order:** processa o nó após os filhos.\n  - **Level-order:** processa nós por nível (usando fila).\n\n## Implementação (Python)\n\nA seguir, um exemplo simples de implementação de uma **Árvore Binária de Busca (BST)**:\n\n```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinarySearchTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        # Insere um novo valor na árvore\n        if self.root is None:\n            self.root = Node(value)\n        else:\n            self._insert(self.root, value)\n\n    def _insert(self, current, value):\n        if value < current.value:\n            if current.left is None:\n                current.left = Node(value)\n            else:\n                self._insert(current.left, value)\n        elif value > current.value:\n            if current.right is None:\n                current.right = Node(value)\n            else:\n                self._insert(current.right, value)\n\n    def search(self, value):\n        # Busca um valor na árvore\n        return self._search(self.root, value)\n\n    def _search(self, current, value):\n        if current is None or current.value == value:\n            return current\n        if value < current.value:\n            return self._search(current.left, value)\n        return self._search(current.right, value)\n\n    def inorder(self):\n        # Travessia em ordem (in-order)\n        self._inorder(self.root)\n\n    def _inorder(self, node):\n        if node:\n            self._inorder(node.left)\n            print(node.value, end=\" \")\n            self._inorder(node.right)\n\n# Exemplo de uso\nbst = BinarySearchTree()\nbst.insert(8)\nbst.insert(3)\nbst.insert(10)\nbst.insert(1)\nbst.insert(6)\n\nprint(\"Travessia em ordem (in-order):\")\nbst.inorder()  # Saída: 1 3 6 8 10\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Estrutura eficiente para **busca, inserção e remoção**.\n- Facilita **organização hierárquica de dados**.\n- Pode ser balanceada para desempenho otimizado.\n\n**Desvantagens:**\n- Pode se tornar **desequilibrada**, afetando a performance (em casos degenerados, vira uma lista).\n- **Implementação mais complexa** que estruturas lineares.\n\n## Uso e Aplicações\n\n- **Árvores de decisão** em Machine Learning.\n- **Índices de bancos de dados** (B-Trees, AVL, Red-Black Trees).\n- **Sistemas de arquivos e diretórios**.\n- **Compiladores** (análise sintática em árvores de sintaxe).\n- **Busca em grafos** (DFS e BFS em árvores).\n\n## Complexidade\n\n| Operação  | Tempo Médio | Pior Caso | Descrição |\n|------------|--------------|------------|------------|\n| Busca      | O(log n)     | O(n)       | Encontrar um valor na árvore |\n| Inserção   | O(log n)     | O(n)       | Inserir novo nó |\n| Remoção    | O(log n)     | O(n)       | Remover nó mantendo estrutura |\n| Travessia  | O(n)         | O(n)       | Visitar todos os nós |\n| Espaço     | O(n)         | O(n)       | Armazena n nós |\n"
    },
    {
      "name": "Binary Search Tree",
      "contentMarkdown": "# Binary Search Tree (Árvore Binária de Busca - BST)\n\nUma **Binary Search Tree (BST)** é uma estrutura de dados em forma de **árvore binária** na qual cada nó possui **no máximo dois filhos**, e segue uma propriedade fundamental:  \n**para qualquer nó, todos os valores da subárvore esquerda são menores que o valor do nó, e todos os valores da subárvore direita são maiores.**\n\n## Conceito\n\nA BST é usada principalmente para **armazenar dados ordenados** de forma que operações como **busca, inserção e remoção** possam ser realizadas de maneira eficiente — geralmente em **O(log n)** tempo em árvores balanceadas.  \nEla combina a estrutura hierárquica das árvores com a lógica de ordenação das listas ordenadas.\n\nUma boa analogia é uma **lista telefônica organizada por nomes**: se você está procurando “Maria”, você pode ignorar todos os nomes que vêm depois de “Maria” ao olhar para a esquerda, e todos que vêm antes ao olhar para a direita.\n\n### Estrutura Interna\n\nCada nó da BST contém:\n- **Valor (key):** o dado armazenado.\n- **Left (esquerda):** ponteiro para o nó filho com valor menor.\n- **Right (direita):** ponteiro para o nó filho com valor maior.\n\n![Diagrama ilustrativo de uma Binary Search Tree](https://i.postimg.cc/Kj0kkk4j/bst.png)\n\n## Operações Comuns\n\n- **Inserção:** adiciona um novo nó na posição correta mantendo a ordem.\n- **Busca:** localiza um valor seguindo a propriedade da BST.\n- **Remoção:** exclui um nó e reorganiza a árvore mantendo a estrutura válida.\n- **Travessias:** percorre a árvore em diferentes ordens (pre, in, post, level).\n\n## Implementação (Python)\n\nAbaixo um exemplo funcional de uma **Binary Search Tree** simples:\n\n```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\nclass BinarySearchTree:\n    def __init__(self):\n        self.root = None\n\n    def insert(self, value):\n        # Insere um novo valor na BST\n        if self.root is None:\n            self.root = Node(value)\n        else:\n            self._insert(self.root, value)\n\n    def _insert(self, node, value):\n        if value < node.value:\n            if node.left is None:\n                node.left = Node(value)\n            else:\n                self._insert(node.left, value)\n        elif value > node.value:\n            if node.right is None:\n                node.right = Node(value)\n            else:\n                self._insert(node.right, value)\n\n    def search(self, value):\n        # Busca um valor na árvore\n        return self._search(self.root, value)\n\n    def _search(self, node, value):\n        if node is None or node.value == value:\n            return node\n        if value < node.value:\n            return self._search(node.left, value)\n        return self._search(node.right, value)\n\n    def inorder(self):\n        # Travessia em ordem crescente\n        self._inorder(self.root)\n\n    def _inorder(self, node):\n        if node:\n            self._inorder(node.left)\n            print(node.value, end=\" \")\n            self._inorder(node.right)\n\n# Exemplo de uso\nbst = BinarySearchTree()\nfor v in [8, 3, 10, 1, 6, 9, 14]:\n    bst.insert(v)\n\nprint(\"Travessia em ordem:\")\nbst.inorder()  # Saída: 1 3 6 8 9 10 14\n\n# Busca de elemento\nprint(\"\\nExiste o valor 6?\", bst.search(6) is not None)\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Busca, inserção e remoção eficientes (em média O(log n)).\n- Mantém os dados ordenados naturalmente.\n- Permite travessias que retornam dados em **ordem crescente**.\n\n**Desvantagens:**\n- Pode **se tornar desbalanceada**, resultando em desempenho O(n).\n- Necessita de **reorganização** (balanceamento) para manter eficiência.\n- Implementação mais complexa que listas ou arrays.\n\n## Uso e Aplicações\n\n- **Índices de bancos de dados.**\n- **Sistemas de ordenação dinâmica.**\n- **Árvores de busca em compiladores e linguagens.**\n- **Algoritmos de autocompletar ou sugestões baseadas em prefixos.**\n- **Estruturas derivadas como AVL e Red-Black Trees.**\n\n## Complexidade\n\n| Operação  | Tempo Médio | Pior Caso | Descrição |\n|------------|--------------|------------|------------|\n| Busca      | O(log n)     | O(n)       | Localizar valor |\n| Inserção   | O(log n)     | O(n)       | Inserir novo nó |\n| Remoção    | O(log n)     | O(n)       | Remover mantendo estrutura |\n| Travessia  | O(n)         | O(n)       | Percorrer todos os nós |\n| Espaço     | O(n)         | O(n)       | Armazenar n nós |\n"
    },
    {
      "name": "Hash Table",
      "contentMarkdown": "# Hash Tables\n\nUma **Hash Table** (ou Tabela Hash) é uma estrutura de dados que armazena pares de **chave-valor**, permitindo acesso extremamente rápido aos dados através de uma função hash. Ela mapeia chaves para posições específicas em um array, oferecendo busca, inserção e remoção em tempo médio constante O(1).\n\n## Como Funciona\n\nO funcionamento de uma Hash Table baseia-se em uma **função hash**, que é um algoritmo que transforma uma chave (que pode ser uma string, número ou qualquer tipo de dado) em um **índice numérico** dentro de um array subjacente. Este índice determina onde o valor correspondente será armazenado.\n\nQuando você deseja armazenar um par chave-valor, a função hash processa a chave e gera um índice. O valor é então inserido nesta posição do array. Para recuperar o valor, a mesma função hash é aplicada à chave, gerando o mesmo índice, permitindo acesso direto ao valor armazenado.\n\n**Analogia:** Imagine uma biblioteca onde cada livro tem um código único. Em vez de procurar livro por livro, você usa uma fórmula matemática que converte o código em um número de prateleira específico, levando você diretamente ao livro desejado.\n\n### Colisões\n\nUm desafio importante nas Hash Tables são as **colisões**, que ocorrem quando duas chaves diferentes geram o mesmo índice após passar pela função hash. Existem duas estratégias principais para resolver colisões:\n\n**Encadeamento (Chaining):** Cada posição do array contém uma lista ligada. Quando ocorre uma colisão, o novo elemento é adicionado à lista naquela posição.\n\n**Endereçamento Aberto (Open Addressing):** Quando uma colisão ocorre, o algoritmo procura a próxima posição disponível no array seguindo uma sequência de sondagem (linear, quadrática ou duplo hash).\n\n![Diagrama ilustrativo de uma Hash Table com encadeamento](https://i.postimg.cc/vT0gggDW/hash-map.png)\n\n## Operações Comuns\n\n- **Inserção (put/set):** Aplica a função hash à chave para determinar o índice e armazena o par chave-valor naquela posição\n- **Busca (get):** Usa a função hash para localizar o índice da chave e retorna o valor associado\n- **Remoção (delete/remove):** Localiza a chave através da função hash e remove o par chave-valor da estrutura\n- **Atualização:** Substitui o valor de uma chave existente aplicando a função hash para localizar a posição\n- **Verificação de existência (contains/has):** Verifica se uma determinada chave existe na tabela\n\n## Implementação (Python)\n\n```python\nclass HashTable:\n    def __init__(self, tamanho=10):\n        # Inicializa um array de listas para encadeamento\n        self.tamanho = tamanho\n        self.tabela = [[] for _ in range(tamanho)]\n    \n    def _funcao_hash(self, chave):\n        # Função hash simples usando módulo\n        return hash(chave) % self.tamanho\n    \n    def inserir(self, chave, valor):\n        # Calcula o índice usando a função hash\n        indice = self._funcao_hash(chave)\n        \n        # Verifica se a chave já existe e atualiza\n        for i, (k, v) in enumerate(self.tabela[indice]):\n            if k == chave:\n                self.tabela[indice][i] = (chave, valor)\n                return\n        \n        # Se não existe, adiciona novo par chave-valor\n        self.tabela[indice].append((chave, valor))\n    \n    def buscar(self, chave):\n        # Calcula o índice\n        indice = self._funcao_hash(chave)\n        \n        # Procura a chave na lista encadeada\n        for k, v in self.tabela[indice]:\n            if k == chave:\n                return v\n        \n        # Retorna None se não encontrar\n        return None\n    \n    def remover(self, chave):\n        # Calcula o índice\n        indice = self._funcao_hash(chave)\n        \n        # Remove o par chave-valor se encontrado\n        for i, (k, v) in enumerate(self.tabela[indice]):\n            if k == chave:\n                del self.tabela[indice][i]\n                return True\n        \n        return False\n\n# Exemplo de uso\ntabela = HashTable()\ntabela.inserir(\"nome\", \"João\")\ntabela.inserir(\"idade\", 25)\ntabela.inserir(\"cidade\", \"São Paulo\")\n\nprint(tabela.buscar(\"nome\"))  # Saída: João\nprint(tabela.buscar(\"idade\"))  # Saída: 25\n\ntabela.remover(\"idade\")\nprint(tabela.buscar(\"idade\"))  # Saída: None\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n- Acesso extremamente rápido aos dados com complexidade O(1) no caso médio\n- Inserção e remoção eficientes\n- Ideal para implementar caches, índices de banco de dados e dicionários\n- Flexibilidade para armazenar diferentes tipos de chaves\n\n**Desvantagens:**\n\n- Desempenho degrada para O(n) no pior caso quando há muitas colisões\n- Consumo de memória pode ser alto devido ao array subjacente\n- Não mantém ordem de inserção (em implementações básicas)\n- Necessidade de uma boa função hash para distribuição uniforme\n- Redimensionamento pode ser custoso quando a tabela fica cheia\n\n## Uso e Aplicações\n\nHash Tables são amplamente utilizadas em diversos cenários:\n\n- **Bancos de dados:** Índices para acelerar consultas e buscas\n- **Caches:** Armazenamento temporário de resultados computacionais (memoização)\n- **Compiladores:** Tabelas de símbolos para armazenar variáveis e funções\n- **Roteadores de rede:** Tabelas de roteamento para encaminhamento rápido de pacotes\n- **Detecção de duplicatas:** Verificar rapidamente se um elemento já foi processado\n- **Contadores de frequência:** Contar ocorrências de elementos em conjuntos de dados\n- **Implementação de Sets e Maps:** Estruturas fundamentais em linguagens de programação\n- **Autenticação:** Armazenamento de senhas com hash criptográfico\n- **Sistemas de gerenciamento de sessões:** Identificação rápida de sessões de usuários\n\n## Complexidade\n\n**Complexidade de Tempo:**\n\n- **Busca:** O(1) caso médio, O(n) pior caso (quando todas as chaves colidem)\n- **Inserção:** O(1) caso médio, O(n) pior caso\n- **Remoção:** O(1) caso médio, O(n) pior caso\n\n**Complexidade de Espaço:**\n\n- **O(n):** Onde n é o número de pares chave-valor armazenados\n\nO desempenho de uma Hash Table depende fortemente da qualidade da função hash e do fator de carga (relação entre número de elementos e tamanho do array). Para manter o desempenho O(1), é comum redimensionar a tabela quando o fator de carga ultrapassa um limite (geralmente 0.7 ou 70%)."
    },
    {
      "name": "Graph",
      "contentMarkdown": "# Grafos\n\nUm **Grafo** é uma estrutura de dados não-linear composta por um conjunto de **vértices** (ou nós) conectados por **arestas** (ou arcos). Os grafos são fundamentais para modelar relações entre objetos, permitindo representar conexões complexas como redes sociais, mapas de rotas, circuitos elétricos e dependências entre tarefas.\n\n## Como Funciona\n\nUm grafo é formalmente definido como G = (V, E), onde V é o conjunto de **vértices** e E é o conjunto de **arestas**. Cada aresta conecta dois vértices, representando algum tipo de relacionamento ou conexão entre eles.\n\nOs grafos podem ser **direcionados** (digrafos), onde as arestas têm uma direção específica (A → B), ou **não-direcionados**, onde as conexões são bidirecionais (A ↔ B). Além disso, as arestas podem ter **pesos** associados, representando custos, distâncias ou capacidades.\n\n**Analogia:** Pense em um grafo como um mapa de uma cidade. Os vértices são os cruzamentos ou pontos de interesse, e as arestas são as ruas que os conectam. Se as ruas têm direção única, temos um grafo direcionado; se podemos ir em ambas as direções, é não-direcionado. As distâncias das ruas representam os pesos das arestas.\n\n### Tipos de Grafos\n\n**Grafo Simples:** Não possui laços (arestas que conectam um vértice a si mesmo) nem arestas múltiplas entre os mesmos vértices.\n\n**Grafo Completo:** Cada vértice está conectado a todos os outros vértices.\n\n**Grafo Bipartido:** Os vértices podem ser divididos em dois conjuntos disjuntos, onde as arestas só conectam vértices de conjuntos diferentes.\n\n**Árvore:** Um grafo conectado e acíclico (sem ciclos).\n\n![Diagrama ilustrativo de diferentes tipos de grafos](https://i.postimg.cc/sxTQQQ1Z/grafo.png)\n\n## Operações Comuns\n\n- **Adição de vértice:** Insere um novo nó no grafo\n- **Adição de aresta:** Cria uma conexão entre dois vértices existentes\n- **Remoção de vértice:** Remove um nó e todas as arestas conectadas a ele\n- **Remoção de aresta:** Elimina uma conexão específica entre dois vértices\n- **Busca de vértice:** Verifica se um determinado vértice existe no grafo\n- **Busca de aresta:** Verifica se existe conexão entre dois vértices específicos\n- **Obtenção de vizinhos:** Retorna todos os vértices adjacentes a um determinado vértice\n- **Verificação de conectividade:** Determina se dois vértices estão conectados direta ou indiretamente\n\n## Implementação (Python)\n\n```python\nclass Grafo:\n    def __init__(self, direcionado=False):\n        # Dicionário para armazenar a lista de adjacência\n        self.vertices = {}\n        self.direcionado = direcionado\n    \n    def adicionar_vertice(self, vertice):\n        # Adiciona um novo vértice se não existir\n        if vertice not in self.vertices:\n            self.vertices[vertice] = []\n    \n    def adicionar_aresta(self, origem, destino, peso=1):\n        # Garante que ambos os vértices existam\n        self.adicionar_vertice(origem)\n        self.adicionar_vertice(destino)\n        \n        # Adiciona a aresta\n        self.vertices[origem].append((destino, peso))\n        \n        # Se não é direcionado, adiciona a aresta reversa\n        if not self.direcionado:\n            self.vertices[destino].append((origem, peso))\n    \n    def remover_vertice(self, vertice):\n        # Remove o vértice e todas as arestas conectadas\n        if vertice in self.vertices:\n            # Remove arestas que apontam para este vértice\n            for v in self.vertices:\n                self.vertices[v] = [\n                    (destino, peso) for destino, peso in self.vertices[v] \n                    if destino != vertice\n                ]\n            # Remove o vértice\n            del self.vertices[vertice]\n    \n    def remover_aresta(self, origem, destino):\n        # Remove aresta específica\n        if origem in self.vertices:\n            self.vertices[origem] = [\n                (d, p) for d, p in self.vertices[origem] if d != destino\n            ]\n        \n        # Se não é direcionado, remove também a aresta reversa\n        if not self.direcionado and destino in self.vertices:\n            self.vertices[destino] = [\n                (d, p) for d, p in self.vertices[destino] if d != origem\n            ]\n    \n    def exibir_grafo(self):\n        # Exibe a representação do grafo\n        for vertice in self.vertices:\n            vizinhos = [f\"{dest}({peso})\" for dest, peso in self.vertices[vertice]]\n            print(f\"{vertice} -> {', '.join(vizinhos) if vizinhos else 'sem conexões'}\")\n\n# Exemplo de uso\ngrafo = Grafo(direcionado=False)\n\n# Adicionando vértices e arestas\ngrafo.adicionar_aresta(\"A\", \"B\", 5)\ngrafo.adicionar_aresta(\"A\", \"C\", 3)\ngrafo.adicionar_aresta(\"B\", \"D\", 2)\ngrafo.adicionar_aresta(\"C\", \"D\", 4)\ngrafo.adicionar_aresta(\"D\", \"E\", 1)\n\nprint(\"Estrutura do grafo:\")\ngrafo.exibir_grafo()\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n- Modelagem natural de relacionamentos complexos entre entidades\n- Flexibilidade para representar diversos tipos de conexões e estruturas\n- Algoritmos poderosos disponíveis para análise e traversal\n- Adequado para resolver problemas de otimização como menor caminho\n- Escalabilidade para representar redes muito grandes\n\n**Desvantagens:**\n\n- Complexidade computacional alta para algumas operações em grafos grandes\n- Consumo de memória pode ser significativo em grafos densos\n- Implementação mais complexa comparada a estruturas lineares\n- Algoritmos podem ter alta complexidade de tempo dependendo do problema\n- Dificuldade de visualização em grafos grandes ou muito conectados\n\n## Uso e Aplicações\n\nGrafos são utilizados em uma ampla variedade de aplicações:\n\n- **Redes sociais:** Modelar conexões entre usuários, análise de influência e detecção de comunidades\n- **Sistemas de navegação:** Encontrar rotas mais curtas em mapas (GPS, aplicativos de trânsito)\n- **Redes de computadores:** Roteamento de dados, topologia de rede e detecção de falhas\n- **Compiladores:** Análise de dependências entre módulos e otimização de código\n- **Bioinformática:** Análise de redes de proteínas, sequenciamento de DNA e árvores filogenéticas\n- **Sistemas de recomendação:** Relacionar usuários e produtos baseado em preferências\n- **Jogos:** Representar mapas, sistemas de movimento e árvores de decisão de IA\n- **Logística:** Otimização de rotas de entrega, planejamento de supply chain\n- **Análise de dependências:** Gerenciamento de pacotes de software, cronogramas de projetos\n- **Detecção de fraudes:** Análise de padrões suspeitos em transações financeiras\n\n## Complexidade\n\n**Representação por Lista de Adjacência:**\n\n- **Espaço:** O(V + E) onde V é o número de vértices e E o número de arestas\n- **Adição de vértice:** O(1)\n- **Adição de aresta:** O(1)\n- **Verificação de aresta:** O(grau do vértice)\n- **Remoção de vértice:** O(V + E)\n\n**Representação por Matriz de Adjacência:**\n\n- **Espaço:** O(V²)\n- **Adição de vértice:** O(V²) - necessita redimensionar a matriz\n- **Adição de aresta:** O(1)\n- **Verificação de aresta:** O(1)\n- **Remoção de vértice:** O(V²)\n\nA escolha da representação (lista vs matriz de adjacência) depende da densidade do grafo e das operações mais frequentes. Listas de adjacência são preferíveis para grafos esparsos, enquanto matrizes são melhores para grafos densos quando verificações de aresta são frequentes."
    },
    {
      "name": "Heap",
      "contentMarkdown": "# Heap\n\nUm **Heap** é uma estrutura de dados baseada em árvore binária que satisfaz a propriedade do heap: em um **Max Heap**, cada nó pai possui valor maior ou igual aos seus filhos; em um **Min Heap**, cada nó pai possui valor menor ou igual aos seus filhos. Heaps são fundamentais para implementar filas de prioridade e algoritmos de ordenação eficientes como o Heap Sort.\n\n## Como Funciona\n\nO Heap é uma **árvore binária completa**, o que significa que todos os níveis estão completamente preenchidos, exceto possivelmente o último, que é preenchido da esquerda para a direita. Esta característica permite que heaps sejam implementados eficientemente usando arrays, onde para um elemento no índice `i`, o filho esquerdo está em `2i + 1` e o filho direito em `2i + 2`, enquanto o pai está em `(i - 1) / 2`.\n\nA **propriedade do heap** garante que o elemento de maior prioridade (máximo ou mínimo) esteja sempre na raiz da árvore, permitindo acesso em tempo constante. Quando elementos são inseridos ou removidos, a estrutura realiza operações de **heapify** para restaurar a propriedade do heap, movendo elementos para cima (bubble up) ou para baixo (bubble down) conforme necessário.\n\n### Tipos de Heap\n\n**Min Heap:** O valor de cada nó é menor ou igual aos valores de seus filhos. A raiz contém o menor elemento.\n\n**Max Heap:** O valor de cada nó é maior ou igual aos valores de seus filhos. A raiz contém o maior elemento.\n\n![Diagrama ilustrativo de um Min Heap e Max Heap](https://i.postimg.cc/fy8tttkc/heaps.png)\n\n## Operações Comuns\n\n- **Inserção (Push):** Adiciona um novo elemento ao final do array e executa bubble up para manter a propriedade do heap\n- **Remoção do Topo (Pop):** Remove o elemento da raiz, substitui pela última folha e executa bubble down\n- **Peek:** Retorna o elemento de maior prioridade (raiz) sem removê-lo\n- **Heapify:** Converte um array desordenado em um heap válido\n- **Increase/Decrease Key:** Modifica o valor de um elemento e restaura a propriedade do heap\n- **Merge:** Combina dois heaps em um único heap\n\n## Implementação (Python)\n\n```python\nclass MinHeap:\n    def __init__(self):\n        self.heap = []\n    \n    def parent(self, i):\n        \"\"\"Retorna o índice do pai\"\"\"\n        return (i - 1) // 2\n    \n    def left_child(self, i):\n        \"\"\"Retorna o índice do filho esquerdo\"\"\"\n        return 2 * i + 1\n    \n    def right_child(self, i):\n        \"\"\"Retorna o índice do filho direito\"\"\"\n        return 2 * i + 2\n    \n    def swap(self, i, j):\n        \"\"\"Troca dois elementos no heap\"\"\"\n        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n    \n    def insert(self, valor):\n        \"\"\"Insere um novo valor no heap\"\"\"\n        self.heap.append(valor)\n        self._bubble_up(len(self.heap) - 1)\n    \n    def _bubble_up(self, i):\n        \"\"\"Move o elemento para cima até satisfazer a propriedade do heap\"\"\"\n        while i > 0 and self.heap[i] < self.heap[self.parent(i)]:\n            self.swap(i, self.parent(i))\n            i = self.parent(i)\n    \n    def extract_min(self):\n        \"\"\"Remove e retorna o menor elemento (raiz)\"\"\"\n        if len(self.heap) == 0:\n            return None\n        \n        if len(self.heap) == 1:\n            return self.heap.pop()\n        \n        # Guarda o mínimo e substitui pela última folha\n        min_val = self.heap[0]\n        self.heap[0] = self.heap.pop()\n        self._bubble_down(0)\n        \n        return min_val\n    \n    def _bubble_down(self, i):\n        \"\"\"Move o elemento para baixo até satisfazer a propriedade do heap\"\"\"\n        min_index = i\n        \n        while True:\n            left = self.left_child(i)\n            right = self.right_child(i)\n            \n            # Encontra o menor entre pai, filho esquerdo e direito\n            if left < len(self.heap) and self.heap[left] < self.heap[min_index]:\n                min_index = left\n            \n            if right < len(self.heap) and self.heap[right] < self.heap[min_index]:\n                min_index = right\n            \n            # Se o pai já é o menor, termina\n            if min_index == i:\n                break\n            \n            self.swap(i, min_index)\n            i = min_index\n    \n    def peek(self):\n        \"\"\"Retorna o menor elemento sem removê-lo\"\"\"\n        return self.heap[0] if self.heap else None\n    \n    def size(self):\n        \"\"\"Retorna o tamanho do heap\"\"\"\n        return len(self.heap)\n\n# Exemplo de uso\nheap = MinHeap()\nheap.insert(10)\nheap.insert(5)\nheap.insert(20)\nheap.insert(1)\n\nprint(heap.peek())         # Saída: 1\nprint(heap.extract_min())  # Saída: 1\nprint(heap.extract_min())  # Saída: 5\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n\n- Acesso ao elemento de maior prioridade em tempo constante O(1)\n- Inserção e remoção eficientes em O(log n)\n- Implementação simples usando arrays, sem necessidade de ponteiros\n- Uso eficiente de memória devido à representação em array\n- Ideal para implementar filas de prioridade\n- Boa localidade de cache por usar arrays contíguos\n\n**Desvantagens:**\n\n- Busca de elementos arbitrários é lenta O(n)\n- Não mantém os elementos completamente ordenados\n- Não suporta busca eficiente de elementos específicos\n- Remoção de elementos do meio é custosa O(n)\n- Merge de heaps pode ser ineficiente comparado a outras estruturas como Fibonacci Heap\n\n## Uso e Aplicações\n\n- **Filas de Prioridade:** Gerenciamento de tarefas com diferentes prioridades em sistemas operacionais\n- **Algoritmo de Dijkstra:** Encontrar o caminho mais curto em grafos\n- **Heap Sort:** Algoritmo de ordenação in-place com complexidade O(n log n)\n- **Algoritmo de Huffman:** Compressão de dados através de codificação\n- **Merge K Sorted Lists:** Combinar múltiplas listas ordenadas eficientemente\n- **Mediana em Stream de Dados:** Calcular mediana de dados em tempo real usando dois heaps\n- **Escalonamento de Processos:** Sistemas operacionais usam heaps para gerenciar processos\n- **Algoritmo de Prim:** Encontrar árvore geradora mínima em grafos\n- **Event-Driven Simulation:** Gerenciar eventos ordenados por timestamp\n\n## Complexidade\n\n**Complexidade de Tempo:**\n\n- **Peek (acesso à raiz):** O(1) - acesso direto ao primeiro elemento\n- **Inserção:** O(log n) - pode precisar subir até a raiz\n- **Remoção do topo:** O(log n) - pode precisar descer até as folhas\n- **Heapify (construção):** O(n) - constrói heap a partir de array\n- **Busca:** O(n) - necessita percorrer toda a estrutura\n- **Decrease/Increase Key:** O(log n) - ajuste e bubble up/down\n\n**Complexidade de Espaço:**\n\n- **Armazenamento:** O(n) - usa array para armazenar n elementos\n- **Operações:** O(1) - operações são realizadas in-place, sem memória adicional significativa"
    },
    {
      "name": "Prefix Sums",
      "contentMarkdown": "# Prefix Sums\n\nPrefix Sums (Somas de Prefixo) é uma técnica de pré-processamento que permite calcular rapidamente a soma de elementos em qualquer intervalo de um array. Em vez de recalcular somas repetidamente, criamos um array auxiliar onde cada posição armazena a soma acumulada de todos os elementos anteriores, transformando consultas de intervalo que normalmente levariam O(n) em operações O(1).\n\n## Como Funciona\n\nO conceito fundamental do Prefix Sums é construir um **array de somas acumuladas** a partir de um array original. Para cada índice `i`, o array de prefix sums armazena a soma de todos os elementos desde o início do array até a posição `i`.\n\nA ideia é simples: se sabemos a soma total até a posição `j` e a soma total até a posição `i-1`, podemos obter a soma do intervalo `[i, j]` simplesmente subtraindo essas duas somas acumuladas. Isso elimina a necessidade de iterar pelo intervalo a cada consulta.\n\n### Construção do Array de Prefix Sums\n\nDado um array original `arr[0...n-1]`, criamos um array `prefix[0...n]` onde:\n- `prefix[0] = 0` (convenção para facilitar cálculos)\n- `prefix[i] = prefix[i-1] + arr[i-1]` para `i >= 1`\n\nDessa forma, `prefix[i]` representa a soma de todos os elementos de `arr[0]` até `arr[i-1]`.\n\n### Calculando a Soma de um Intervalo\n\nPara calcular a soma dos elementos no intervalo `[L, R]` (inclusivo) do array original:\n\n**Soma(L, R) = prefix[R+1] - prefix[L]**\n\nEsta operação é executada em **tempo constante O(1)**, independentemente do tamanho do intervalo.\n\n![Diagrama ilustrativo de Prefix Sums mostrando array original e array acumulado](https://i.postimg.cc/Hn6cccj3/prefix-sum.png)\n\n## Operações Comuns\n\n- **Construção do Array de Prefix Sums:** Percorre o array original uma vez, calculando as somas acumuladas. Complexidade: O(n)\n- **Consulta de Soma em Intervalo:** Retorna a soma de elementos entre dois índices usando subtração de valores pré-calculados. Complexidade: O(1)\n- **Atualização de Elementos:** Se o array original for modificado, o array de prefix sums precisa ser reconstruído ou atualizado. Complexidade: O(n) para reconstrução completa\n- **Múltiplas Consultas:** Ideal para cenários onde há muitas consultas de soma em diferentes intervalos do mesmo array\n\n## Implementação (Python)\n\n```python\nclass PrefixSum:\n    def __init__(self, arr):\n        \"\"\"\n        Constrói o array de prefix sums a partir do array original.\n        \n        Args:\n            arr: Lista de números\n        \"\"\"\n        self.n = len(arr)\n        # Array de prefix sums com tamanho n+1\n        self.prefix = [0] * (self.n + 1)\n        \n        # Construir o array de somas acumuladas\n        for i in range(self.n):\n            self.prefix[i + 1] = self.prefix[i] + arr[i]\n    \n    def soma_intervalo(self, L, R):\n        \"\"\"\n        Retorna a soma dos elementos no intervalo [L, R] (inclusivo).\n        \n        Args:\n            L: Índice inicial (0-indexed)\n            R: Índice final (0-indexed)\n        \n        Returns:\n            Soma dos elementos no intervalo\n        \"\"\"\n        if L < 0 or R >= self.n or L > R:\n            raise ValueError(\"Intervalo inválido\")\n        \n        return self.prefix[R + 1] - self.prefix[L]\n\n\n# Exemplo de uso\narr = [3, 1, 4, 1, 5, 9, 2, 6]\nps = PrefixSum(arr)\n\n# Consultar soma em diferentes intervalos\nprint(f\"Soma [0, 3]: {ps.soma_intervalo(0, 3)}\")  # 3+1+4+1 = 9\nprint(f\"Soma [2, 5]: {ps.soma_intervalo(2, 5)}\")  # 4+1+5+9 = 19\nprint(f\"Soma [4, 7]: {ps.soma_intervalo(4, 7)}\")  # 5+9+2+6 = 22\n\n# Implementação alternativa simplificada\ndef construir_prefix_sum(arr):\n    \"\"\"Versão simplificada que retorna apenas o array de prefix sums.\"\"\"\n    prefix = [0]\n    for num in arr:\n        prefix.append(prefix[-1] + num)\n    return prefix\n\n# Uso simplificado\narr = [2, 4, 6, 8, 10]\nprefix = construir_prefix_sum(arr)\n# Soma do intervalo [1, 3]: arr[1] + arr[2] + arr[3] = 4 + 6 + 8 = 18\nsoma = prefix[4] - prefix[1]\nprint(f\"Soma [1, 3]: {soma}\")  # 18\n```\n\n## Vantagens e Desvantagens\n\n**Vantagens:**\n- Consultas de soma em intervalo extremamente rápidas (O(1))\n- Simples de implementar e entender\n- Baixo overhead de memória (apenas O(n) adicional)\n- Ideal para arrays estáticos ou com poucas atualizações\n- Pode ser estendido para 2D (matrizes) e outras variações\n\n**Desvantagens:**\n- Ineficiente para arrays que são frequentemente modificados (requer reconstrução O(n))\n- Não otimizado para outras operações além de soma (mínimo, máximo, etc.)\n- Para arrays dinâmicos com muitas atualizações, estruturas como Segment Tree ou Fenwick Tree são mais adequadas\n- Requer espaço adicional proporcional ao tamanho do array\n\n## Uso e Aplicações\n\n- **Problemas de Programação Competitiva:** Resolução eficiente de problemas envolvendo consultas de soma em subarray\n- **Análise de Séries Temporais:** Cálculo rápido de médias móveis e agregações em janelas de tempo\n- **Processamento de Imagens:** Cálculo de somas em regiões retangulares de imagens (usando Prefix Sum 2D)\n- **Estatísticas e Analytics:** Agregação rápida de métricas em diferentes períodos ou segmentos\n- **Algoritmos de Otimização:** Base para diversos algoritmos como Kadane's' Algorithm modificado\n- **Detecção de Padrões:** Identificação de subarrays com soma específica ou propriedades matemáticas\n- **Sistemas de Cache:** Pré-computação de valores agregados para melhorar performance de consultas\n\n## Complexidade\n\n**Complexidade de Tempo:**\n- **Construção:** O(n) - percorre o array original uma vez para construir o array de prefix sums\n- **Consulta de Soma em Intervalo:** O(1) - apenas uma subtração entre dois valores pré-calculados\n- **Atualização de Elemento:** O(n) - requer reconstrução do array de prefix sums (se necessário)\n- **Múltiplas Consultas:** O(q) para q consultas, cada uma em O(1)\n\n**Complexidade de Espaço:**\n- **Espaço Auxiliar:** O(n) - array adicional para armazenar as somas acumuladas\n- **Espaço Total:** O(n) - considerando o array original e o array de prefix sums\n\nA técnica é especialmente vantajosa quando o número de consultas é muito maior que o número de atualizações, resultando em complexidade amortizada muito eficiente comparada à abordagem ingênua de somar elementos a cada consulta."
    }
  ],
  "page": 0,
  "size": 10,
  "totalElements": 68,
  "totalPages": 7,
  "first": true,
  "last": false
}